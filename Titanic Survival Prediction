# -*- coding: utf-8 -*-

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report,confusion_matrix
from sklearn.preprocessing import StandardScaler

# Step 2: Load the Dataset
data = pd.read_csv('tested.csv')
print(data.head())
print(data.info())
print(data.describe())

# Step 3: Data Preprocessing
# Handle Missing Values
print(data.isnull().sum())
data['Age'].fillna(data['Age'].median(), inplace=True)
data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)

# Feature Engineering
data['FamilySize'] = data['SibSp'] + data['Parch']
data = pd.get_dummies(data, columns=['Sex', 'Embarked'], drop_first=True)
features = ['Pclass', 'Age', 'Fare', 'FamilySize', 'Sex_male', 'Embarked_Q', 'Embarked_S']
X = data[features]
y = data['Survived']
 
# Step 4: Divide data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=40)

# Step 5: Feature Scaling 
scaler = StandardScaler()
X_test.fillna(X_train.mean(), inplace=True)
X_train.fillna(X_train.mean(), inplace=True)
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Step 6: Build and Train a Machine Learning Model (Random Forest)
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)

# Step 7: Evaluate the Model
y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

print(f'Accuracy: {accuracy}')
print(f'Confusion Matrix:\n{conf_matrix}')
print(f'Classification Report:\n{class_report}')

